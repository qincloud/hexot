<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hbase教程]]></title>
    <url>%2Fhexot%2F2018%2F06%2F20%2Fhbase%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[hbase官方网站 hbase下载地址 博主使用的是hbase-2.0.0 安装hbase前需要先行安装hadoop 把包放到/usr/local下并解压12[root@master ~]# cp hbase-2.0.0-bin.tar.gz /usr/local[root@master ~]# tar zxvf hbase-2.0.0-bin.tar.gz 解压完毕后需要修改两个地方的配置 conf文件夹下配置hbase-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;!-- 需要和hadoop的hdfs配置一致 --&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; conf文件夹下配置hbase-env.sh 添加如下配置 123export JAVA_HOME=/usr/local/jdk1.8export HBASE_CLASSPATH=/usr/local/hbase-2.0.0/conf export HBASE_MANAGES_ZK=true #是否启动自带的zookeeper 配置完成后到bin目录下启动hbase 1234567891011121314[root@master bin]# ./start-hbase.sh[root@master ~]# jps21616 DataNode21873 SecondaryNameNode3890 Jps31667 HMaster21460 NameNode22212 NodeManager24324 Worker24181 Master31591 HQuorumPeer1305 Main22060 ResourceManager31758 HRegionServer 启动后有HRegionServer,HQuorumPeer,HMaster这三个进程 然后访问http://localhost:16010 如果有东西就表示完成了. 停止hbase&amp;进入hbase shell&amp;查看hdfs下的hbase1234567891011121314151617[root@master bin]# ./stop-hbase.sh[root@master bin]# hbase shell[root@master ~]# hadoop fs -ls /hbase18/06/20 21:34:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableFound 12 itemsdrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/.hbckdrwxr-xr-x - root supergroup 0 2018-06-20 20:44 /hbase/.tmpdrwxr-xr-x - root supergroup 0 2018-06-20 20:59 /hbase/MasterProcWALsdrwxr-xr-x - root supergroup 0 2018-06-20 20:44 /hbase/WALsdrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/archivedrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/corruptdrwxr-xr-x - root supergroup 0 2018-06-20 20:44 /hbase/data-rw-r--r-- 3 root supergroup 42 2018-06-20 20:43 /hbase/hbase.id-rw-r--r-- 3 root supergroup 7 2018-06-20 20:43 /hbase/hbase.versiondrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/mobdirdrwxr-xr-x - root supergroup 0 2018-06-20 20:59 /hbase/oldWALsdrwx--x--x - root supergroup 0 2018-06-20 20:43 /hbase/staging]]></content>
  </entry>
  <entry>
    <title><![CDATA[从paxos到zookeeper分布式一致性原理与实践(笔记,重点,读后感)]]></title>
    <url>%2Fhexot%2F2018%2F06%2F08%2F%E4%BB%8Epaxos%E5%88%B0zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E7%AC%94%E8%AE%B0-%E9%87%8D%E7%82%B9-%E8%AF%BB%E5%90%8E%E6%84%9F%2F</url>
    <content type="text"><![CDATA[本书一共有８个章节 第一章: 分布式架构 1~15页 第二章: 一致性协议 17~37页 第三章: Paxos的工程实践 39~58页 第四章: ZooKeeper与Paxos 59～78页 第五章: 使用ZooKeeper 79~162页 第六章: ZooKeeper的典型应用场景 163~242页 第七章: ZooKeeper的技术内幕 243页~376页 第八章: Zookeeper运维379~405页 第一章分布式架构1.集中式的特点:又一台或多台计算机组成的中心节点。 2.分布式的特点:分布式系统是一个硬件或软件组件分布在不同的网络计算机上,彼此之间仅仅通过消息传递进行通信和协调的系统。 3.事物具有4个特征:原子性,一致性,隔离性,持久性,简称事物的ACID特性。 4.分布式事物 5.CAP定理:一个分布式系统不可能同时满足一致性,可用性,分区容错性最多只能满足其中两项 6.BASE理论:]]></content>
  </entry>
  <entry>
    <title><![CDATA[上传项目到github]]></title>
    <url>%2Fhexot%2F2018%2F06%2F02%2F%E4%B8%8A%E4%BC%A0%E9%A1%B9%E7%9B%AE%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[首先到github上面注册一个账号 1.上传github的具体命令 设置git的账号和名字 12git config --global user.email "2877408638@qq.com"git config --global user.name "qincloud" 到项目文件夹下123456789git init #初始化gitgit add . #添加所有文件到gitgit commit -m "first commit" #提交本地git#git@github.com:qincloud/cloudtest.git是github的地址#这一步可能需要输入github的账号和密码git remote add origin git@github.com:qincloud/cloudtest.gitgit push -u origin master ＃推到github]]></content>
      <categories>
        <category>git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spring data 源码阅读]]></title>
    <url>%2Fhexot%2F2018%2F05%2F30%2Fspring-data-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[spring-data官方网站 然后将spring-data的源代码全部下载下来]]></content>
  </entry>
  <entry>
    <title><![CDATA[jersey介绍,应用]]></title>
    <url>%2Fhexot%2F2018%2F05%2F11%2Fjersey%E4%BB%8B%E7%BB%8D-%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[参考博客 1.Jersey框架一：Jersey RESTful WebService框架简介 2.Jersey 简单试用 3.Jersey Client api 基本使用 首先附上jersey官网和api文档地址 jersey官网 jersey官方api地址 stackoverflow jersey是基于JAX-RS api实现的自己的api JAX-RS是JAVA EE6 引入的一个新技术。 JAX-RS即Java API for RESTful Web Services，是一个Java 编程语言的应用程序接口，支持按照表述性状态转移（REST）架构风格创建Web服务。JAX-RS使用了Java SE5引入的Java注解来简化Web服务的客户端和服务端的开发和部署。 附上JAX-RS api源代码和示例有兴趣研究JAR-RS的同学可以看看 下面是百度百科给的例子 web.xml的设置：12345678910111213141516171819&lt;!--定义Jersey的拦截器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;JerseyServlet&lt;/servlet-name&gt; &lt;servlet-class&gt; com.sun.jersey.spi.spring.container.servlet.SpringServlet &lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;com.sun.jersey.config.property.packages&lt;/param-name&gt; &lt;!--服务类所在的文件夹 --&gt; &lt;param-value&gt;com.mirrors.action&lt;/param-value&gt;&lt;!-- 之所以我定义为com.mirrors.action就是说明此包中类的作用类似于struts中action层类的作用--!&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;JerseyServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/new/*&lt;/url-pattern&gt;&lt;!--项目服务总体前缀 --&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; StudentAction.java一些代码： 12345678910111213141516 @Component @Path("/student")//处理student对象的签注 public class StudentAction &#123; private StudentDao studentdao; public void setStudentdaoStudentDao studentdao)&#123; this.studentdao =studentdao; &#125; @GET//获取方式 @Path("getStudentInfo")//最后前缀 @Produces(&#123; MediaType.APPLICATION_JSON &#125;)//返回类型为一个Student对象的JSON数组 public List&lt;Student&gt; getTrade()&#123; return studentdao.getStudent(); &#125;&#125; 这样一个GET方式的处理就结束了，接下来就是前台提取方式，你可以通过JS控制JSON数组在页面的呈现方式。Jersey共计有4中处理方式，即：@GET,@POST,@DELETE,@PUT。由于Jersey中文资料较少。想学习的可以通过官网API学习。]]></content>
      <categories>
        <category>webservice</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kylin实战(一)]]></title>
    <url>%2Fhexot%2F2018%2F05%2F07%2Fkylin%E5%AE%9E%E6%88%98-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[配置kylin环境前请现确保hadoop,hbase,hive,zookeeper等环境的配置]]></content>
  </entry>
  <entry>
    <title><![CDATA[kafka java调用]]></title>
    <url>%2Fhexot%2F2018%2F05%2F06%2Fkafka-java%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[首先附上kafka Api文档 kafkaApi官方文档 打开文档就看到了kafka所有的包如下 org.apache.kafka.clients.consumerorg.apache.kafka.clients.producerorg.apache.kafka.commonorg.apache.kafka.common.configorg.apache.kafka.common.errorsorg.apache.kafka.common.serializationorg.apache.kafka.connect.connectororg.apache.kafka.connect.dataorg.apache.kafka.connect.errorsorg.apache.kafka.connect.sinkorg.apache.kafka.connect.sourceorg.apache.kafka.connect.storageorg.apache.kafka.connect.transformsorg.apache.kafka.connect.utilorg.apache.kafka.streamsorg.apache.kafka.streams.errorsorg.apache.kafka.streams.kstreamorg.apache.kafka.streams.processororg.apache.kafka.streams.state kafka生产者和消费者简单示例]]></content>
      <categories>
        <category>kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka初级教程]]></title>
    <url>%2Fhexot%2F2018%2F05%2F04%2Fkafka%E5%88%9D%E7%BA%A7%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.kafka环境配置1.1 下载kafkakafka官方网站 kafka官方下载页面 我下载的是kafka_2.12-1.0.1.tgz(点击下载链接即可下载) 下载完成后解压到/usr/local/下1234$ mv kafka_2.12-1.0.1.tgz /usr/local/$ cd /usr/local/$ tar -zxvf kafka_2.12-1.0.1.tgz$ mv kafka_2.12-1.0.1 kafka 1.2 下载zookeeperzookeeper下载地址 下载完成后解压到/usr/local 1.3 配置文件修改到zookeeper/conf下修改zoo.cfg文件 修改内容如下 12345tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeperclientPort=2181 #端口 然后修改kafka的配置文件 kafka/config/server.properties文件,内容如下。 12345678910111213141516171819broker.id=0advertised.listeners=PLAINTEXT://master:9092listeners=PLAINTEXT://master:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/data/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181 #要和zookeeper配置的端口一致zookeeper.connection.timeout.ms=6000 创建2个新文件夹并授权 1234[root@localhost config]# mkdir /data/kafka-logs[root@localhost config]# mkdir /data/zookeeper_data[root@localhost config]# chown lzq996298643:lzq996298643 -R /data/kafka-logs[root@localhost config]# chown lzq996298643:lzq996298643 -R /data/zookeeper_data 启动kafka自带的zookeeper和kafka启动 12345678910111213141516171819202122232425262728293031323334[root@localhost bin]# cd /usr/local/kafka/bin[root@localhost bin]# ll总用量 128-rwxr-xr-x. 1 root root 1335 2月 22 06:26 connect-distributed.sh-rwxr-xr-x. 1 root root 1332 2月 22 06:26 connect-standalone.sh-rwxr-xr-x. 1 root root 861 2月 22 06:26 kafka-acls.sh-rwxr-xr-x. 1 root root 873 2月 22 06:26 kafka-broker-api-versions.sh-rwxr-xr-x. 1 root root 864 2月 22 06:26 kafka-configs.sh-rwxr-xr-x. 1 root root 945 2月 22 06:26 kafka-console-consumer.sh-rwxr-xr-x. 1 root root 944 2月 22 06:26 kafka-console-producer.sh-rwxr-xr-x. 1 root root 871 2月 22 06:26 kafka-consumer-groups.sh-rwxr-xr-x. 1 root root 948 2月 22 06:26 kafka-consumer-perf-test.sh-rwxr-xr-x. 1 root root 869 2月 22 06:26 kafka-delete-records.sh-rwxr-xr-x. 1 root root 863 2月 22 06:26 kafka-log-dirs.sh-rwxr-xr-x. 1 root root 862 2月 22 06:26 kafka-mirror-maker.sh-rwxr-xr-x. 1 root root 886 2月 22 06:26 kafka-preferred-replica-election.sh-rwxr-xr-x. 1 root root 959 2月 22 06:26 kafka-producer-perf-test.sh-rwxr-xr-x. 1 root root 874 2月 22 06:26 kafka-reassign-partitions.sh-rwxr-xr-x. 1 root root 868 2月 22 06:26 kafka-replay-log-producer.sh-rwxr-xr-x. 1 root root 874 2月 22 06:26 kafka-replica-verification.sh-rwxr-xr-x. 1 root root 7579 2月 22 06:26 kafka-run-class.sh-rwxr-xr-x. 1 root root 1376 2月 22 06:26 kafka-server-start.sh-rwxr-xr-x. 1 root root 975 2月 22 06:26 kafka-server-stop.sh-rwxr-xr-x. 1 root root 870 2月 22 06:26 kafka-simple-consumer-shell.sh-rwxr-xr-x. 1 root root 945 2月 22 06:26 kafka-streams-application-reset.sh-rwxr-xr-x. 1 root root 863 2月 22 06:26 kafka-topics.sh-rwxr-xr-x. 1 root root 958 2月 22 06:26 kafka-verifiable-consumer.sh-rwxr-xr-x. 1 root root 958 2月 22 06:26 kafka-verifiable-producer.sh-rwxr-xr-x. 1 root root 1722 2月 22 06:26 trogdor.shdrwxr-xr-x. 2 root root 4096 2月 22 06:26 windows-rwxr-xr-x. 1 root root 867 2月 22 06:26 zookeeper-security-migration.sh-rwxr-xr-x. 1 root root 1393 2月 22 06:26 zookeeper-server-start.sh-rwxr-xr-x. 1 root root 978 2月 22 06:26 zookeeper-server-stop.sh-rwxr-xr-x. 1 root root 968 2月 22 06:26 zookeeper-shell.sh bin目录下面有zookeeper和kafka的启动脚本文件 可以直接使用kafka自带的zookeeper 12[root@localhost bin]# ./zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties[root@localhost bin]# ./kafka-server-start.sh /usr/local/kafka/config/server.properties 当然也可以启动你自己下载的zookeeper 1.4 运行kafka遇到的问题server.properties配置文件中下面两行最好设置本机ip地址不要设置localhost advertised.listeners=PLAINTEXT://master:9092 listeners=PLAINTEXT://master:9092 运行./kafka-server-start.sh /usr/local/kafka/config/server.properties然后访问http://master:9092没有报错就说明启动成功了 2.使用kafka2.1 命令行中测试kafka2.1.1创建一个消息创建者1[root@master bin]# ./kafka-console-producer.sh --broker-list 192.168.0.128:9092 --top test 2.1.2创建一个消息消费者1[root@master bin]# ./kafka-console-consumer.sh --zookeeper 192.168.0.128:2181 --topic test --from-beginning 2.2 kafka命令脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bashsource /etc/profile#前台启动zkif [ $1 = "zk" ]thenzookeeper-server-start.sh /data/kafka_2.11-0.10.1.0/config/zookeeper.properties#后台启动zkelif [ $1 = "zkbg" ]thennohup zookeeper-server-start.sh /data/kafka_2.11-0.10.1.0/config/zookeeper.properties &gt;/dev/null 2&gt;&amp;1 &amp;#关闭zkelif [ $1 = "zkstop" ]thenzookeeper-server-stop.sh#前台启动kafkaelif [ $1 = "kafka" ]thenkafka-server-start.sh /data/kafka_2.11-0.10.1.0/config/server.properties#后台启动kafkaelif [ $1 = "kafkabg" ]thennohup kafka-server-start.sh /data/kafka_2.11-0.10.1.0/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;#关闭kafkaelif [ $1 = "kafkastop" ]thenkafka-server-stop.shelif [ $1 = "consumer" ] #创建一个消费者thenkafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic $2elif [ $1 = "producer" ] #创建一个生产者thenkafka-console-producer.sh --broker-list master:9092 --topic $2elif [ $1 = "create" ]thenkafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic $2 #创建topicelif [ $1 = "list" ]thenkafka-topics.sh --list --zookeeper localhost:2181 #查看topicelif [ $1 = "delete" ]thenkafka-topics.sh --delete --zookeeper localhost:2181 --topic $2 #删除topicelseecho "parameter invalid"fi]]></content>
      <categories>
        <category>kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch初级教程]]></title>
    <url>%2Fhexot%2F2018%2F04%2F14%2Felasticsearch%E5%88%9D%E7%BA%A7%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.安装elasticsearch先去elasticsearch官方网站下载elasticsearch 由于本人平台是centos7,所以本人选择了tar包 下载完成后解压到/usr/local/下 然后进入elasticsearch/config文件夹下修改elasticsearch.yml文件 12345network.host: 192.168.2.215 #配置ip地址http.port: 9200 #配置端口号discovery.zen.ping.unicast.hosts: ["192.168.2.215"] #配置ip地址 配置完成后创建一个es用户 12345678910$ useradd es#创建用户完成后切换到root用户打开/etc/security/limits.conf文件$ gedit /etc/security/limits.conf添加以下两行es hard nofile 65536es soft nofile 65536 然后进入elasticsearch/bin文件夹下切换到es用户启动elasticsearch 1$ ./elasticsearch 然后访问elasticsearch.yml文件里配置的ip地址+端口看到一串json字符串就表示启动成功了,如下 123456789101112131415&#123; &quot;name&quot; : &quot;e17kn5H&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;q1W9ZuXySmag-mmqbAjYYw&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.2.3&quot;, &quot;build_hash&quot; : &quot;c59ff00&quot;, &quot;build_date&quot; : &quot;2018-03-13T10:06:29.741383Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.2.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 2.curl命令操作elasticsearch2.1 创建和删除Index2.1.1 创建一个weather Index12[lzq996298643@localhost ~]$ curl -X PUT '192.168.2.215:9200/qincloud'&#123;"acknowledged":true,"shards_acknowledged":true,"index":"qincloud"&#125; 2.1.2 删除weather index1curl -X DELETE '192.168.2.215:9200/qincloud' 2.2 中文分词器12]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pivot与unpivot使用示例]]></title>
    <url>%2Fhexot%2F2018%2F04%2F13%2Fpivot%E4%B8%8Eunpivot%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[一.下面sql创建一个视图 sql sql 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282CREATE OR REPLACE VIEW TJ_XQ_NLAS SELECT "NF" , "ZM" , "ZMMC" , "FIV" , "SIX" , "SEVEN", "EIGHT", "NIGHT", "QT" FROM ( SELECT * FROM ( SELECT '2017' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201712' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2016' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201612' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2015' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201512' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2014' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201412' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2013' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201312' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2012' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201212' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) ); 二.unpivot示范 12345678910111213141516171819202122232425262728293031323334353637383940414243444546select 分类 , 年龄 , 年份2012, 年份2013, 年份2014, 年份2015, 年份2016, 年份2017from ( select zm , zmmc as 分类 , ln as 年龄 , sum(case when nf = '2012' then num else 0 end) as 年份2012, sum(case when nf = '2013' then num else 0 end) as 年份2013, sum(case when nf = '2014' then num else 0 end) as 年份2014, sum(case when nf = '2015' then num else 0 end) as 年份2015, sum(case when nf = '2016' then num else 0 end) as 年份2016, sum(case when nf = '2017' then num else 0 end) as 年份2017 from ( select zm , zmmc, nf , ln , num from ( select * from tj_xq_nl ) xq unpivot(num for ln in(fiv as '50后', six as '60后', seven as '70后', eight as '80后', night as '90后', qt as '其它')) l where zmmc is not null ) group by zm , zmmc, ln order by zm, ln )]]></content>
      <categories>
        <category>sql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo部署到github]]></title>
    <url>%2Fhexot%2F2018%2F04%2F13%2Fhexo%E9%83%A8%E7%BD%B2%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[hexo官方文档 hexo官方网站主题 在生成以及部署文章之前，需要安装一个扩展：npm install hexo-deployer-git –save然后在hexo服务器文件夹下运行命令: hexo d -g]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker教程]]></title>
    <url>%2Fhexot%2F2018%2F01%2F10%2Fdocker%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一.docker的安装和docker仓库使用docker的安装作者环境是centos7,建议玩docker小伙伴们也在centos7环境上,centos7必须是64位哦 直接运行下面命令安装centos71yum install docker hub.docker.com的注册dockerhub的官方网址是https://hub.docker.com/ 在上面注册一个帐号就可以上传镜像了,和git提交上传代码是一样的． dockerhub的代码是开源的也可以自己搭建一个docker仓库,这个在以后会有专门的教程]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[superset安装教程]]></title>
    <url>%2Fhexot%2F2017%2F12%2F03%2Fsuperset%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装superset本人环境centos7 需要安装python,centos7有自带python 一.安装python 的依赖库和pip1$ yum install libffi-devel python-devel python-pip python-wheel openssl-devel libsasl2-devel openldap-develhi 二.Python virtualenv环境12$ pip install virtualenv #安装virtualenv$ virtualenv venv #进入virtualenv环境 三.安装superset12$ pip install #更新pip$ pip install superset #安装superset 四.设置superset账号和密码123456789$ fabmanager create-admin --app supersetUsername [admin]: adminUser first name [admin]: liaoUser last name [user]: zhqEmail [admin@fab.org]: 996298643@qq.comPassword: Repeat for confirmation: Recognized Database Authentications.Admin User admin created. 五.更新运行初始化运行superset1234567891011$ superset db upgrade #更新superset$ superset init #初始化superset$ superset runserver #运行supersetStarting server with command: gunicorn -w 2 --timeout 60 -b 0.0.0.0:8088 --limit-request-line 0 --limit-request-field_size 0 superset:app[2017-12-03 14:52:30 +0000] [23159] [INFO] Starting gunicorn 19.7.1[2017-12-03 14:52:30 +0000] [23159] [INFO] Listening at: http://0.0.0.0:8088 (23159)[2017-12-03 14:52:30 +0000] [23159] [INFO] Using worker: sync[2017-12-03 14:52:30 +0000] [23164] [INFO] Booting worker with pid: 23164[2017-12-03 14:52:30 +0000] [23165] [INFO] Booting worker with pid: 23165 http://localhost:8088 访问superset]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo安装实验]]></title>
    <url>%2Fhexot%2F2017%2F12%2F02%2Ftest%2F</url>
    <content type="text"><![CDATA[hexo小白傻瓜安装教程参考博客 安装hexo之前必须安装node.js和git 以下将从我的环境下说明如何安装node.js和hexo 我的电脑环境是centos7 首先下载和安装node.js 第一步下载node.jsnode.js下载地址(我已经上传到csdn) 第二步安装node.js解压后使用命令 1$ tar --strip-components 1 -xzvf node-v* -C /usr/local 可直接copy到/usr/local对应文件夹下面 使用以下命令如果和下面的结果相同说明已经安装好了node.js 12345$ npm -v5.5.1$ node -vv9.2.0 安装好了node.js后就可以开始安装hexo一.下载安装hexo12$ npm install -g hexo$ npm install -g hexo-cli 安装好hexo以后，在终端输入：1$ hexo 如果没有提示找不到该命令说明安装成功。 二.初始化hexo// 建立一个博客文件夹，并初始化博客，为文件夹的名称，可以随便起名字 $ hexo init ${文件夹} // 进入hexo博客文件夹，${文件夹}为文件夹的名称 $ cd ${文件夹} // node.js的命令，根据博客既定的dependencies配置安装所有的依赖包 $ npm install // 安装hexo admin界面功能 $ npm install –save hexo-admin-qiniu 1234$ hexo init /home/lzq996298643/services/hexo$ cd /home/lzq996298643/services/hexo$ npm install$ npm install --save hexo-admin-qiniu 安装完成后可以在/home/lzq996298643/services/hexo看到博客文件夹 三.发表一篇文章和启动hexo必须要在hexo初始化的文件夹下面(/home/lzq996298643/services/hexo)亲测// 新建一篇文章 hexo new “文章标题” //启动hexo hexo server 如果看到以下输出就表明启动成功1234$ hexo server(node:6187) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. http://localhost:4000 或 http://localhost:4000/admin 访问]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhexot%2F2017%2F01%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
</search>
