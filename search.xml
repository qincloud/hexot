<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux常用命令查询]]></title>
    <url>%2Fhexot%2F2018%2F12%2F01%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[find命令locate命令scp命令rcp命令 find命令使用示范:123lzq@lzqcloud:~$ find /home/lzq -name jgzfxt #/home/lzq目录下找jgzfxt文件夹lzq@lzqcloud:~$ find /home/lzq -name Jbxx.java #/home/lzq目录下找Jbxx.java文件lzq@lzqcloud:~$ find /home/lzq -name *Jbxx* #使用通配符*(0或者任意多个)按照文件特征查找 123456789find / -amin -10 # 查找在系统中最后10分钟访问的文件(access time)find / -atime -2 # 查找在系统中最后48小时访问的文件find / -empty # 查找在系统中为空的文件或者文件夹find / -group cat # 查找在系统中属于 group为cat的文件find / -mmin -5 # 查找在系统中最后5分钟里修改过的文件(modify time)find / -mtime -1 #查找在系统中最后24小时里修改过的文件find / -user fred #查找在系统中属于fred这个用户的文件find / -size +10000c #查找出大于10000000字节的文件(c:字节，w:双字，k:KB，M:MB，G:GB)find / -size -1000k #查找出小于1000KB的文件使用混合查找方式查找文件参数有： ！，-and(-a)，-or(-o)123find /tmp -size +10000c -and -mtime +2 #在/tmp目录下查找大于10000字节并在最后2分钟内修改的文件 find / -user fred -or -user george #在/目录下查找用户是fred或者george的文件文件 find /tmp ! -user panda #在/tmp目录中查找所有不属于panda用户的文件find参数大全-name filename #查找名为filename的文件-perm #按执行权限来查找-user username #按文件属主来查找-group groupname #按组来查找-mtime -n +n #按文件更改时间来查找文件，-n指n天以内，+n指n天以前-atime -n +n #按文件访问时间来查GIN: 0px”&gt;-ctime -n +n #按文件创建时间来查找文件，-n指n天以内，+n指n天以前-nogroup #查无有效属组的文件，即文件的属组在/etc/groups中不存在-nouser #查无有效属主的文件，即文件的属主在/etc/passwd中不存-newer f1 !f2 找文件，-n指n天以内，+n指n天以前-ctime -n +n #按文件创建时间来查找文件，-n指n天以内，+n指n天以前-nogroup #查无有效属组的文件，即文件的属组在/etc/groups中不存在-nouser #查无有效属主的文件，即文件的属主在/etc/passwd中不存-newer f1 !f2 #查更改时间比f1新但比f2旧的文件-type b/d/c/p/l/f #查是块设备、目录、字符设备、管道、符号链接、普通文件-size n[c] #查长度为n块[或n字节]的文件-depth #使查找在进入子目录前先行查找完本目录-fstype #查更改时间比f1新但比f2旧的文件-type b/d/c/p/l/f #查是块设备、目录、字符设备、管道、符号链接、普通文件-size n[c] #查长度为n块[或n字节]的文件-depth #使查找在进入子目录前先行查找完本目录-fstype #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到-mount #查文件时不跨越文件系统mount点-follow #如果遇到符号链接文件，就跟踪链接所指的文件-cpio %; #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到-mount #查文件时不跨越文件系统mount点-follow #如果遇到符号链接文件，就跟踪链接所指的文件-cpio #对匹配的文件使用cpio命令，将他们备份到磁带设备中-prune #忽略某个目录locate命令使用示范: 12 scp命令使用示范: 12 rcp命令使用示范: 12]]></content>
  </entry>
  <entry>
    <title><![CDATA[WebKit代码导读]]></title>
    <url>%2Fhexot%2F2018%2F11%2F25%2FWebKit%E4%BB%A3%E7%A0%81%E5%AF%BC%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[webkit内核是现代浏览器主要使用的内核,阅读webKit内核代码有助于优化前端代码性能.]]></content>
  </entry>
  <entry>
    <title><![CDATA[t-io websocket兼容ie8]]></title>
    <url>%2Fhexot%2F2018%2F11%2F13%2Ft-io-websocket%E5%85%BC%E5%AE%B9ie8%2F</url>
    <content type="text"><![CDATA[最近系统有些业务需要用到websocket来进行开发,后来我有一个同事选择了国产t-io框架. t-io框架是国产nio框架,和neety非常像,也很轻量,整体代码量很少,学习成本也低,但是后来把t-io集成到项目里的工作任务就交给了我. 但是我们的项目要求websocket必须要兼容ie8,但是后来发现ie8识别不了t-io传输过来的http协议头老是报错,后来重写了t-io,（WsServerStarter,HttpResponseEncoder,WsServerAioHandler）这三个类但是主要是从写HttpResponseEncoder这个类的encode方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[总结读后感]]></title>
    <url>%2Fhexot%2F2018%2F10%2F28%2F%E4%B8%8D%E8%A6%81%E8%AE%A9%E6%97%A0%E6%95%88%E5%8A%AA%E5%8A%9B%E6%AF%81%E4%BA%86%E4%BD%A0-%E6%80%BB%E7%BB%93%E8%AF%BB%E5%90%8E%E6%84%9F%2F</url>
    <content type="text"><![CDATA[第九章]]></content>
  </entry>
  <entry>
    <title><![CDATA[23个设计模式总结]]></title>
    <url>%2Fhexot%2F2018%2F10%2F20%2F23%E4%B8%AA%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.创建型模式创建型模式有抽象工厂模式, 工厂方法模式, 单例模式, 原型模式 2.结构型模式3.行为模式]]></content>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq搭建]]></title>
    <url>%2Fhexot%2F2018%2F08%2F08%2Frabbitmq%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一．配置erlang环境rabbitmq是用erlang语言编写的消息队列,Erlang([‘ə:læŋ])是一种通用的面向并发的编程语言. Erlang的官方网站上下载erlang博主下载的是otp_src_21.0.tar.gz版本点击下载即可. 下载完成后把文件解压出来进入文件夹编译安装erlang 123[root@localhost otp_src_21.0]# chmod +x configure #授权configure文件[root@localhost otp_src_21.0]# configure --prefix=/usr/local/erlang #执行configure并指定安装目录[root@localhost otp_src_21.0]# make &amp;&amp; make install #编译与安装 如果没有报错,然后再去指定的安装文件夹下看到了bin和lib文件夹,那么就安装完成了. 然后配置环境变量在/etc/profile文件夹下加入 export ERL_HOME=/usr/local/erlang export PATH=:$ERL_HOME/bin 加入好环境变量之后执行erl命令如果进入erl命令行就说明erlang完成搭建了 12345[lzq996298643@localhost ~]$ erlErlang/OTP 21 [erts-10.0] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]Eshell V10.0 (abort with ^G)1&gt; 二. 编译安装rabbitmq二.一 下载rabbitmq源代码包RabbitMQ官方网站可以找到下载的源代码地址 博主下载的是3.7.7的版本的RabbitMQ下载地址这里可以下载源代码也可以下载rpm包和window下的exe软件安装包. 本宝宝下载的是源代码包,下载完成后解压软件包,然后进入解压的文件夹,打开Makefile文件,找到RMQ_ERLAPP_DIR这一段然后修改成要编译的地址 我修改到了/usr/local文件夹下 RMQ_ERLAPP_DIR ?= /usr/local/rabbitmq_server 修改完后执行make &amp;&amp; make install 123make[2]: elixir：命令未找到 GEN escript/rabbitmqctl/bin/sh:行1: mix: 未找到命令 但是报了上面的错误了,是因为elixir没有安装 二.二 elixir的安装Elixir 是一个基于 Erlang 虚拟机的函数式、面向并行的通用编程语言。Elixir 以 Erlang 为基础，支持分布式、高容错、实时应用程序的开发，同时亦对其进行扩展使之借助宏实现元编程，并通过协议支持多态。 首先现将elixir项目在github上面克隆下来git clone https://github.com/elixir-lang/elixir.git 1[lzq996298643@localhost 开源代码]$ git clone https://github.com/elixir-lang/elixir.git 进入elixir文件夹,然后直接make clean test,make install,执行make test可能会有错误(去谷歌搜索可以找到答案). 12[lzq996298643@localhost elixir]$ make clean test[lzq996298643@localhost elixir]$ make install 安装完exlixir在去make安装rabbitemq报了下面的错误,意思就是只支持exlixir1.6.0版本的 (Mix) You’re trying to run :rabbitmqctl on Elixir v1.8.0-dev but it has declared in its mix.exs file it supports only Elixir ~&gt; 1.6.0 git branch -a 查看有什么其它版本,然后替换为１.6.0的版本.再重新make安装exlixir 123456789101112131415161718192021222324252627282930313233343536[lzq996298643@localhost elixir]$ git branch -a #查看项目版本有多少* master remotes/origin/HEAD -&gt; origin/master remotes/origin/emj/deps-paths-level remotes/origin/jv-no-19 remotes/origin/master remotes/origin/mm/compiler-warnings-errors remotes/origin/mm/records remotes/origin/v1.0 remotes/origin/v1.1 remotes/origin/v1.2 remotes/origin/v1.3 remotes/origin/v1.4 remotes/origin/v1.5 remotes/origin/v1.6 remotes/origin/v1.7 [lzq996298643@localhost elixir]$ git checkout origin/v1.6 #替换为1.6版本Note: checking out 'origin/v1.6'.You are in 'detached HEAD' state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout.If you want to create a new branch to retain commits you create, you maydo so (now or later) by using -b with the checkout command again. Example: git checkout -b new_branch_nameHEAD 目前位于 b6d27b5... Ignore unknown child info in Logger.Translator (#7892)[lzq996298643@localhost elixir]$ cat VERSION #查看版本1.6.6[lzq996298643@localhost elixir]$ make clean test[lzq996298643@localhost elixir]$ make install 结束了elixir的安装到rabbitmq源代码源文件夹下直接make &amp;&amp; make install 1[root@localhost rabbitmq]# make &amp;&amp; make install 二.三 启动rabbitmq和安装web管理界面创建/etc/rabbitmq目录,这个必须要创建且不能修改 然后到rabbitmq安装目录下sbin执行rabbitmq-plugins enable rabbitmq_management 12345678910111213[root@localhost sbin]# rabbitmq-plugins enable rabbitmq_managementThe following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchApplying plugin configuration to rabbit@localhost...The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchset 3 plugins.Offline change; changes will take effect at broker restart. 然后新建/etc/rabbitmq/rabbitmq-env.conf文件添加以下内容 RABBITMQ_LOG_BASE=/data/rabbitmq/logs #日志存放地址RABBITMQ_MNESIA_BASE=/data/rabbitmq/mnesia #mnesia数据库地址 配置完成后到安装目录sbin目录下启动rabbitmq服务123[root@localhost sbin]# ./rabbitmq-server -detachedWARNING: Removing trailing slash from RABBITMQ_LOG_BASEWarning: PID file not written; -detached was passed. rabbitemq默认服务端口是5672,http界面默认的端口是15672 123[root@localhost rabbitmq]# lsof -i:5672COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbeam.smp 12831 root 69u IPv6 129168 0t0 TCP *:amqp (LISTEN) 执行上面命令如果有东西,说明服务已经启动了. 打开 http://localhost:15672/ 地址 默认帐号密码都是guest,登录进入.]]></content>
  </entry>
  <entry>
    <title><![CDATA[深入抛析JDK(编译JDK,阅读构建JDK代码)]]></title>
    <url>%2Fhexot%2F2018%2F08%2F04%2F%E6%B7%B1%E5%85%A5%E6%8A%9B%E6%9E%90JDK-%E7%BC%96%E8%AF%91JDK-%E9%98%85%E8%AF%BB%E6%9E%84%E5%BB%BAJDK%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[注:博主是在centos7上面进行编译的. 1.jdk代码管理openjdk源代码官网各个版本的jdk源代码在上面都有 openjdk源代码是用一个叫mercurial(轻量级分布式版本控制系统)的工具来管理源代码的 首先下载安装mercurial的源代码下载完成后解压下来进入源代码文件夹 12[root@localhost opnesource]# tar -zxvf mercurial-4.6.tar.gz[root@localhost opnesource]# cd mercurial-4.6 打开Ｍakefile文件找到export PREFIX=/usr/local可以指定安装目录修改完成后输入make install命令开始安装. 1[root@localhost mercurial-4.6]# make install 安装完成后输入hg version有以下信息就表示可以了 12345678[root@localhost opensource]# hg version分布式软件配置管理工具 - 水银 (版本 4.6)(see https://mercurial-scm.org for more information)Copyright (C) 2005-2018 Matt Mackall and othersThis is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.[root@localhost jdk7u-dev]# 然后用命令将openjdk源代码clone下来 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283[root@localhost jdk]# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev[root@localhost jdk]# cd dk7u-dev #进入代码文件夹[root@localhost dk7u-dev]# chmod 755 get_source.sh #进入代码文件夹授权get_source.sh文件[root@localhost jdk7u-dev]# ./get_source.sh# Repos: jaxp jaxws jdk hotspot Starting on jaxpStarting on jaxwsStarting on jdkStarting on hotspot# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev/hotspot hotspot正在请求全部修改正在增加修改集正在增加清单事务中止!完成回滚中止: stream ended unexpectedly (got 10152 bytes, expected 19512)# exit code 255# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev/jaxp jaxp正在请求全部修改正在增加修改集正在增加清单正在增加文件改变已增加 1138 个修改集，包含 5685 个改变，修改了 4097 个文件new changesets 6ce5f4757bde:9af3447d957eupdating to branch default2078 files updated, 0 files merged, 0 files removed, 0 files unresolved# exit code 0# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev/jaxws jaxws正在请求全部修改正在增加修改集正在增加清单正在增加文件改变事务中止!完成回滚中止: stream ended unexpectedly (got 14 bytes, expected 80)# exit code 255# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev/jdk jdk正在请求全部修改正在增加修改集正在增加清单正在增加文件改变已增加 7885 个修改集，包含 66961 个改变，修改了 22185 个文件new changesets 37a05a11f281:70e3553d9d6eupdating to branch default20846 files updated, 0 files merged, 0 files removed, 0 files unresolved# exit code 0# Repos: ./corba . ./hotspot ./jaxp ./jdk ./langtools Starting on ./corbaStarting on .Starting on ./hotspotStarting on ./jaxpStarting on ./jdkStarting on ./langtools# cd ./corba &amp;&amp; hg pull -u正在拉自 http://hg.openjdk.java.net/jdk7u/jdk7u-dev/corba正在搜索修改没有发现修改# exit code 0# cd ./hotspot &amp;&amp; hg pull -u正在拉自 http://hg.openjdk.java.net/jdk7u/jdk7u-dev/hotspot正在搜索修改没有发现修改# exit code 0# cd ./jaxp &amp;&amp; hg pull -u正在拉自 http://hg.openjdk.java.net/jdk7u/jdk7u-dev/jaxp正在搜索修改没有发现修改# exit code 0# cd . &amp;&amp; hg pull -u正在拉自 http://hg.openjdk.java.net/jdk7u/jdk7u-dev正在搜索修改没有发现修改# exit code 0# cd ./langtools &amp;&amp; hg pull -u正在拉自 http://hg.openjdk.java.net/jdk7u/jdk7u-dev/langtools正在搜索修改没有发现修改# exit code 0# cd ./jdk &amp;&amp; hg pull -u正在拉自 http://hg.openjdk.java.net/jdk7u/jdk7u-dev/jdk正在搜索修改没有发现修改# exit code 0 如果发现有exit code 255应该是下载失败了,需要从新clone 12[root@localhost jdk7u-dev]# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev/hotspot [root@localhost jdk7u-dev]# hg clone http://hg.openjdk.java.net/jdk7u/jdk7u-dev/jaxws 代码确认下载完成后就可以开始编译了. 2.开始编译jdk代码2.1 设置编译环境变量执行下面的命令12345678910111213141516171819202122232425262728293031323334353637383940export LANG=Cexport ALT_BOOTDIR=/usr/local/jdk1.7/ #设置jdkexport ALLOW_DOWNLOADS=trueexport HOTSPOT_BUILD_JOBS=6export ALT_PATALLER_COMPILE_JOBS=6export SKIP_COMPARE_IMAGES=trueexport USE_PRECOMPILED_HEADER=trueexport BUILD_LANGTOOLS=trueexport BUILD_HOTSPOT=true #设置是否编译HOTSPOT模块export BUILD_JDK=true #设置是否编译JDK模块export BUILD_JAXP=true #设置是否编译JAXP模块 export BUILD_JAXWS=true #设置是否编译JAXWS模块export BUILD_CORBA=true #设置是否编译CORBA模块#export SKIP_DEBUG_BUILD=false#export SKIP_FASTDEBUG_BUILD=trueBUILD_DEPLOY=falseBUILD_INSTALL=falseexport ALT_OUTPUTDIR=/root/temp/jdk7u #输出的位置 #export CORBA_DIST=$ALT_OUTPUTDIR/corba/dist#export JAXP_DIST=$ALT_OUTPUTDIR/jaxp/dist#export JAXWS_DIST=$ALT_OUTPUTDIR/jaxws/distunset JAVA_HOME #卸载JAVA_HOMEunset CLASSPATH #卸载CLASSPATHunset JAVA_OPTS 2.2依赖环境安装1234[root@localhost jdk7u-dev]# yum install -y ant ant-nodeps #如果电脑上有ant可以跳过这一步[root@localhost jdk7u-dev]# yum install -y libX11* libX*[root@localhost jdk7u-dev]# yum install -y libXi-devel libXtst-devel libXt-devel freetype* [root@localhost jdk7u-dev]# yum install -y alsa-lib-devel cups-devel 如果不安装这些依赖可能会报错. 2.3开始编译上面的命令执行成功后就可以使用make命令开始编译了.1[root@localhost jdk7u-dev]# make 执行make报了下面这个错误 1234567891011121314Exception in thread &quot;main&quot; java.lang.UnsupportedClassVersionError: org/apache/tools/ant/launch/Launcher : Unsupported major.minor version 52.0 at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) at java.net.URLClassLoader.access$100(URLClassLoader.java:71) at java.net.URLClassLoader$1.run(URLClassLoader.java:361) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:425) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:482) 这是因为设置export ALT_BOOTDIR设置的是JDK1.7的，出现这个错误是因为用高版本的的JDK编译的class放到低版本来执行才会出现这个错误 我编译的JDK是1.7所以要设置1.6的JDK才行 但是本宝宝后来想了想觉得编译1.7的版本太低了,就索性直接编译JDK1.8的吧. 2.3.1下载jdk1.81[root@localhost jdk]# hg clone http://hg.openjdk.java.net/jdk8u/jdk8u-dev 下载步骤同上代码要保证都下载完成,因为这个有点不稳定可能某些模块下载失败,下载失败就手动执行命令下载. 2.3.2编译jdk1.8cd进入1.8代码目录,而且要把环境变量的设置都执行一遍和上面2.1一样,然后授权configure文件，授权后执行configure文件，就会生成一个build文件夹等下编译的内容全部会在这个文件夹下面． 123[root@localhost jdk]# cd jdk8u-dev[root@localhost jdk8u-dev]# chmod +x configure[root@localhost jdk8u-dev]# configure 最后一步执行make 1[root@localhost jdk8u-dev]# make 这一步等时间比较长,执行完后如果没有error就表示编译成功了. 然后打开build下面的那个文件夹 hotspot,jaxp,corba,jaxws,jdk,langtools编译后的文件都有然后打开jdk文件夹 进入bin文件夹 java,javac,jmap,jps等java二进制文件都在然后执行./java -version 1234[root@localhost bin]# ./java -versionopenjdk version "1.8.0-internal"OpenJDK Runtime Environment (build 1.8.0-internal-lzq996298643_2018_08_05_10_25-b00)OpenJDK 64-Bit Server VM (build 25.71-b00, mixed mode) 看到了版本为openjdk version “1.8.0-internal”.]]></content>
  </entry>
  <entry>
    <title><![CDATA[solr源代码阅读与运行调试]]></title>
    <url>%2Fhexot%2F2018%2F07%2F15%2Fsolr%E6%BA%90%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E4%B8%8E%E8%BF%90%E8%A1%8C%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[博主的环境在cenots7下,so以下的环境都是在centos7操作的 由于solr是使用apache ant和ivy进行项目管理的电脑上面需要有ant环境 12[lzq996298643@master ~]$ ant -versionApache Ant(TM) version 1.10.4 compiled on June 19 2018 然后在solr的官方网站上下载solr的源代码 博主下载的是最新的源代码是solr-7.4.0版本的(点击下载) 下载完成后将源代码包解压到开发空间下 进入源代码目录下编译代码 输入ant ivy-bootstrap命令,执行命令会在/.ant/lib/文件夹下载ivy的jar包 然后输入ant eclipse命令,执行命令会在代码目录下生成.classpath和.project文件这样就可以把源代码导入eclipse了 12[root@192 bin]# ant ivy-bootstrap[root@192 bin]# ant eclipse 执行上面的命令如果没有报错就可以导入eclipse了 选择File-&gt;Import-&gt;Existing Projects into Workspace然后选择到项目源代码目录一直下一步 项目导入成功后右键点击项目Properties-&gt;Project Facets勾选Dynamic Web Mudule和java,然后Apply and Close 入下图 然后就会看到项目的源代码结构 eclipse运行solr参考博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[nutch代码研究]]></title>
    <url>%2Fhexot%2F2018%2F07%2F13%2Fnutch%E4%BB%A3%E7%A0%81%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[nutch是java开发的分布式爬虫网络框架,著名的大数据框架hadoop就是的子项目. nutch就是用来爬去数据的没有数据怎么做大数据呢. 首先从nutch官网将源代码下载下来 博主下载的官网最新的版本apache-nutch-2.3.1-src.tar.gz 下载完成后需要把代码导入eclipse,因为nutch是使用ant做的源代码管理的项目,所以eclipse需要安装ivyIDE插件 打开下面菜单 Help -&gt; Install New Software 添加url: http://www.apache.org/dist/ant/ivyde/updatesite/ 然后一步步安装 然后在安装svn插件 添加url: http://subclipse.tigris.org/update_1.8.x 和上面一样一步步安装 然后可以从SVN导入nutch的源代码,也可以直接将源代码导入eclipse. 下面将介绍SVN导入eclipse源代码 打开eclipse菜单 File -&gt; New -&gt; Project -&gt; SVN -&gt; 从SVN检出项目然后输入SVN URL: https://svn.apache.org/repos/asf/nutch/tags/release-2.3.1/ release-2.3.1是代码的版本号,你下载的代码是什么版本就写上多少号 因为是ant构建的项目所以你还需要在你的电脑上面安装ant的工具包 需要把ivy-2.3.0.jar文件copy到ant目录下lib包里面 ivy-2.3.0.jar必须要放到ant的lib的下不然依赖问题不能解决,在项目下输入ant就没有用 然后在nutch目录下输入ant命令下载依赖文件 12[lzq996298643@localhost apache-nutch-2.3.1]$ antBuildfile: /home/lzq996298643/development_space/javaEE2018/nutch/apache-nutch-2.3.1/build.xml]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper java例子]]></title>
    <url>%2Fhexot%2F2018%2F07%2F05%2Fzookeeper-java%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[zookeeper官方网站 从官房网站将zookeeper下载下来解压 然后打开zookeeper的zoo.cfg配置文件 12345tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeperclientPort=2181 #zookeeper开放端口 然后启动zookeeper 进入bin文件夹下1234567891011121314151617181920212223[root@master bin]# ll总用量 36-rwxr-xr-x. 1 dmdba dinstall 232 3月 23 2017 README.txt-rwxr-xr-x. 1 dmdba dinstall 1937 3月 23 2017 zkCleanup.sh-rwxr-xr-x. 1 dmdba dinstall 1056 3月 23 2017 zkCli.cmd-rwxr-xr-x. 1 dmdba dinstall 1534 3月 23 2017 zkCli.sh-rwxr-xr-x. 1 dmdba dinstall 1628 3月 23 2017 zkEnv.cmd-rwxr-xr-x. 1 dmdba dinstall 2696 3月 23 2017 zkEnv.sh-rwxr-xr-x. 1 dmdba dinstall 1089 3月 23 2017 zkServer.cmd-rwxr-xr-x. 1 dmdba dinstall 6773 3月 23 2017 zkServer.sh[root@master bin]# ./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgStarting zookeeper ... STARTED[root@master bin]# lsof -i:2181COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 11660 root 25u IPv6 927786 0t0 TCP *:eforward (LISTEN)[root@master bin]# ./zkServer.sh stopZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgStopping zookeeper ... STOPPED[root@master bin]# lsof -i:2181[root@master bin]# ./zkServer.sh start命令启动zookeeper zookeeper启动默认端口是2181 zookeeper指定配置文件启动 zookeeper的配置文件放在conf文件夹下 可以建立多个zookeeper配置文件 12345678[root@master bin]# ./zkServer.sh start zoo1.cfg ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo1.cfgStarting zookeeper ... STARTED[root@master bin]# lsof -i:2181[root@master bin]# lsof -i:2182COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 12055 root 25u IPv6 939408 0t0 TCP *:cgn-stat (LISTEN) zoo1.cfg文件指定的clientPort为2182 使用”lsof -i:端口”命令测试如果有信息显示说明可以了 java examplezookeeper java官方文档 https://zookeeper.apache.org/doc/r3.4.10/javaExample.pdf java官方教程可以把版本号修改3.4.10是我的zookeeper版本号 下面新建一个maven项目 首先添加maven pom依赖 123456789101112131415161718192021 &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt;&lt;/dependency&gt; 创建zookeeper12345678910public static ZooKeeper createZookeeper(String conectStr, int sessionTime) &#123; try &#123; ZooKeeper zoo = new ZooKeeper(conectStr, sessionTime, null); return zoo; &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println("错误"); return null; &#125; &#125; 获得子节点123456789101112public static void childPath(String node) &#123; try &#123; ZooKeeper zoo = createZookeeper("localhost:2181", 2000); List&lt;String&gt; lists = zoo.getChildren(node, false); for (String path : lists) &#123; System.out.println(path); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println("错误"); &#125;&#125;]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[swagger搭建]]></title>
    <url>%2Fhexot%2F2018%2F06%2F21%2Fswagger%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1.swagger介绍1.1 swagger整体架构博主的环境是centos7以下操作都是在centos7上面完成的. 官网 swagger一款api文档生成工具和swagger类似的工具有阿里妈妈MUX团队开源的rap也是一款API文档工具 rap代码下载地址 当然还有rap的部署教程 swagger要比rap强大的多 swagger它由3部分组成swagger-editor,swagger-ui,swagger-codegen. swagger-editor 文档在线编辑器 swagger-ui 展示api文档 swagger-codegen 生成代码 swagger-validator这个小工具是用来校验生成的文档说明文件是否符合语法规定的。用法非常简单，只需url地址栏，根路径下加上一个参数url，参数内容是放swagger说明文件的地址。即可校验。 以上swagger架构图可以很好说明swagger 1.2 swagger代码swagger-editor,swagger-ui,swagger-codegen也全部都是开源的 swagger-ui代码下载地址 swagger-editor代码下载地址 swagger-ui,swagger-editor是node.js项目 swagger-codegen代码下载地址,swagger-codegen是java项目 2.swagger-editor的搭建首先swagger-editro和swagger-ui是用node.js你电脑上得先有node.js 2.1安装node.js下载node.jsnode.js下载地址(我已经上传到csdn) 安装node.js解压后使用命令 1$ tar --strip-components 1 -xzvf node-v* -C /usr/local 可直接copy到/usr/local对应文件夹下面 使用以下命令如果和下面的结果相同说明已经安装好了node.js 12345$ npm -v5.5.1$ node -vv9.2.0 2.2 swagger-editor开发环境搭建首先将swagger-editor的代码克隆来下然后解压 123456[lzq996298643@master swagger]$ git clone https://github.com/swagger-api/swagger-editor.git正克隆到 &apos;swagger-editor&apos;...remote: Counting objects: 33613, done.remote: Total 33613 (delta 0), reused 0 (delta 0), pack-reused 33612接收对象中: 100% (33613/33613), 194.08 MiB | 127.00 KiB/s, done.处理 delta 中: 100% (18998/18998), done. 代码解压下载完毕后用webstorm将swagger-editor的代码打开 首先安装httpserver1[root@master swagger]$ npm install -g http-server -g是全局安装但是后来发现package.json里面声明依赖了http-server 直接依赖安装就行完全不需要全局安装 到swagger-editor目录下输入npm install或者npm install -save-dev命令都行 12[root@master swagger-editor]$ npm install[root@master swagger-editor]$ npm install -save-dev 如果途中安装失败就换一个npm镜像 淘宝镜像https://registry.npm.taobao.org/另一个镜像http://registry.cnpmjs.org/ 1[root@master swagger-editor]$ npm config set registry http://registry.cnpmjs.org/ 如果还是失败就使用如下命令再安装或者在换个镜像使用如下命令再安装1[root@master swagger-editor]$ npm cache clean --force 安装完毕后就可以启动swagger-editor了 在swagger-editor目录下直接使用http-server命令就行 1[root@master swagger-editor]$ http-server 如果在使用全局http-server命令在swagger-editor的父目录 后面需要加上swagger-editor目录http-server swagger-editor 12345678910111213[root@master swagger]# ll总用量 8drwxrwxr-x. 13 lzq996298643 lzq996298643 4096 6月 23 07:47 swagger-editordrwxrwxr-x. 10 lzq996298643 lzq996298643 4096 6月 22 07:50 swagger-ui[root@master swagger]# http-server swaggerStarting up http-server, serving swaggerAvailable on: http://127.0.0.1:8080 http://192.168.1.103:8080 http://192.168.1.104:8080 http://192.168.173.1:8080 http://192.168.75.1:8080Hit CTRL-C to stop the server 12[root@master swagger-edit]# http-server –p 8888 #这个命令指定端口[root@master swagger]# http-server –p 8888 swagger-edit #这个命令指定端口 点开http://127.0.0.1:8080看到如下内容就表示可以了 3.swagger-ui的搭建同样现将swagger-ui的代码clone下来 1234567[lzq996298643@master swagger]$ git clone https://github.com/swagger-api/swagger-ui.git正克隆到 &apos;swagger-ui&apos;...remote: Counting objects: 23790, done.remote: Compressing objects: 100% (2/2), done.remote: Total 23790 (delta 1), reused 0 (delta 0), pack-reused 23788接收对象中: 100% (23790/23790), 211.49 MiB | 167.00 KiB/s, done.处理 delta 中: 100% (14278/14278), done. 我们主要是需要里面dist文件夹里面的内容 新建一个文件夹将dist文件夹copy进去 然后在新建的文件夹下面执行npm init命令 12345678910111213141516171819202122232425262728293031323334[lzq996298643@master jgzfxt]$ npm initThis utility will walk you through creating a package.json file.It only covers the most common items, and tries to guess sensible defaults.See `npm help json` for definitive documentation on these fieldsand exactly what they do.Use `npm install &lt;pkg&gt;` afterwards to install a package andsave it as a dependency in the package.json file.Press ^C at any time to quit.package name: (jgzfxt) version: (1.0.0) description: entry point: (index.js) test command: git repository: keywords: author: license: (ISC) About to write to /home/lzq996298643/IdeaProjects/swagger/jgzfxt/package.json:&#123; "name": "jgzfxt", "version": "1.0.0", "description": "", "main": "index.js", "scripts": &#123; "test": "echo \"Error: no test specified\" &amp;&amp; exit 1" &#125;, "author": "", "license": "ISC"&#125;Is this OK? (yes) yes 一直回车默认选择就行 然后在新建文件夹下局部安装express框架 12345678[lzq996298643@master jgzfxt]$ npm install expressnpm notice created a lockfile as package-lock.json. You should commit this file.npm WARN jgzfxt@1.0.0 No descriptionnpm WARN jgzfxt@1.0.0 No repository field.+ express@4.16.3added 50 packages from 47 contributors and audited 119 packages in 4.251sfound 0 vulnerabilities 在新建的文件夹下创建index.js输入以下内容 1234567891011var express = require('express'); var app = express(); app.use('/', express.static('dist')); //dist就是swagger-ui拷贝的dist,此处有url路径，如果写/index，则浏览器访问时，也需要port:/index/app.get('/', function (req, res) &#123; res.send('你好'); &#125;); app.listen(3000, function () &#123; //3000 端口，可修改 console.log('Example app listening on port 3000!'); &#125;); 测试运行12[lzq996298643@master jgzfxt]$ node index.js Example app listening on port 3000! 访问http://localhost:3000 修改默认访问的json打开dist文件夹下的index.html 1234567891011121314151617window.onload = function() &#123; // Build a system const ui = SwaggerUIBundle(&#123; url: "https://petstore.swagger.io/v2/swagger.json", dom_id: '#swagger-ui', deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], layout: "StandaloneLayout" &#125;); window.ui = ui;&#125;; 修改这段代码中的url即可]]></content>
  </entry>
  <entry>
    <title><![CDATA[hbase教程]]></title>
    <url>%2Fhexot%2F2018%2F06%2F20%2Fhbase%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[hbase官方网站 hbase下载地址 博主使用的是hbase-2.0.0 安装hbase前需要先行安装hadoop 把包放到/usr/local下并解压12[root@master ~]# cp hbase-2.0.0-bin.tar.gz /usr/local[root@master ~]# tar zxvf hbase-2.0.0-bin.tar.gz 解压完毕后需要修改两个地方的配置 conf文件夹下配置hbase-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;!-- 需要和hadoop的hdfs配置一致 --&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; conf文件夹下配置hbase-env.sh 添加如下配置 123export JAVA_HOME=/usr/local/jdk1.8export HBASE_CLASSPATH=/usr/local/hbase-2.0.0/conf export HBASE_MANAGES_ZK=true #是否启动自带的zookeeper 配置完成后到bin目录下启动hbase 1234567891011121314[root@master bin]# ./start-hbase.sh[root@master ~]# jps21616 DataNode21873 SecondaryNameNode3890 Jps31667 HMaster21460 NameNode22212 NodeManager24324 Worker24181 Master31591 HQuorumPeer1305 Main22060 ResourceManager31758 HRegionServer 启动后有HRegionServer,HQuorumPeer,HMaster这三个进程 然后访问http://localhost:16010 如果有东西就表示完成了. 停止hbase&amp;进入hbase shell&amp;查看hdfs下的hbase1234567891011121314151617[root@master bin]# ./stop-hbase.sh[root@master bin]# hbase shell[root@master ~]# hadoop fs -ls /hbase18/06/20 21:34:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableFound 12 itemsdrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/.hbckdrwxr-xr-x - root supergroup 0 2018-06-20 20:44 /hbase/.tmpdrwxr-xr-x - root supergroup 0 2018-06-20 20:59 /hbase/MasterProcWALsdrwxr-xr-x - root supergroup 0 2018-06-20 20:44 /hbase/WALsdrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/archivedrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/corruptdrwxr-xr-x - root supergroup 0 2018-06-20 20:44 /hbase/data-rw-r--r-- 3 root supergroup 42 2018-06-20 20:43 /hbase/hbase.id-rw-r--r-- 3 root supergroup 7 2018-06-20 20:43 /hbase/hbase.versiondrwxr-xr-x - root supergroup 0 2018-06-20 20:43 /hbase/mobdirdrwxr-xr-x - root supergroup 0 2018-06-20 20:59 /hbase/oldWALsdrwx--x--x - root supergroup 0 2018-06-20 20:43 /hbase/staging]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[从paxos到zookeeper分布式一致性原理与实践(笔记,重点,读后感)]]></title>
    <url>%2Fhexot%2F2018%2F06%2F08%2F%E4%BB%8Epaxos%E5%88%B0zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E7%AC%94%E8%AE%B0-%E9%87%8D%E7%82%B9-%E8%AF%BB%E5%90%8E%E6%84%9F%2F</url>
    <content type="text"><![CDATA[本书一共有８个章节 第一章: 分布式架构 1~15页 第二章: 一致性协议 17~37页 第三章: Paxos的工程实践 39~58页 第四章: ZooKeeper与Paxos 59～78页 第五章: 使用ZooKeeper 79~162页 第六章: ZooKeeper的典型应用场景 163~242页 第七章: ZooKeeper的技术内幕 243页~376页 第八章: Zookeeper运维379~405页 第一章分布式架构1.集中式的特点:又一台或多台计算机组成的中心节点。 2.分布式的特点:分布式系统是一个硬件或软件组件分布在不同的网络计算机上,彼此之间仅仅通过消息传递进行通信和协调的系统。 3.事物具有4个特征:原子性,一致性,隔离性,持久性,简称事物的ACID特性。 4.分布式事物 5.CAP定理:一个分布式系统不可能同时满足一致性,可用性,分区容错性最多只能满足其中两项 6.BASE理论: 第二章一致性协议1.2PC,即Two phase commit 的缩写二阶段提交,阶段一:提交事物请求. 阶段二:执行事物提交 2.3PC,即Three phase commit的缩写就是三阶段提交,它把2PC的提交事物请求拆分为CanCommit,PreCommit,doCommit. 3.PAXOS是一种提高分布式系统容错性的一致性的算法 第三章Paxos的工程实践第四张Zookeeper与Paxos1.Zookeeper是一个开源的分布式解决方案是一个典型的分布式数据一致性解决方案. 2.ZAB(Zookeeper Atomic broadcast)协议是专门为Zookeeper设计的一种支持崩溃恢复的原子广播协议 3.ZAB协议包括两种基本的模式,分别是崩溃的恢复和消息的广播]]></content>
      <categories>
        <category>分布式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[上传项目到github]]></title>
    <url>%2Fhexot%2F2018%2F06%2F02%2F%E4%B8%8A%E4%BC%A0%E9%A1%B9%E7%9B%AE%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[首先到github上面注册一个账号 1.上传github的具体命令 设置git的账号和名字 12git config --global user.email "2877408638@qq.com"git config --global user.name "qincloud" 到项目文件夹下123456789git init #初始化gitgit add . #添加所有文件到gitgit commit -m "first commit" #提交本地git#git@github.com:qincloud/cloudtest.git是github的地址#这一步可能需要输入github的账号和密码git remote add origin git@github.com:qincloud/cloudtest.gitgit push -u origin master ＃推到github]]></content>
      <categories>
        <category>git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spring data 源码阅读]]></title>
    <url>%2Fhexot%2F2018%2F05%2F30%2Fspring-data-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[spring-data官方网站 然后将spring-data的源代码全部下载下来]]></content>
  </entry>
  <entry>
    <title><![CDATA[jersey介绍,应用]]></title>
    <url>%2Fhexot%2F2018%2F05%2F11%2Fjersey%E4%BB%8B%E7%BB%8D-%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[参考博客 1.Jersey框架一：Jersey RESTful WebService框架简介 2.Jersey 简单试用 3.Jersey Client api 基本使用 首先附上jersey官网和api文档地址 jersey官网 jersey官方api地址 stackoverflow jersey是基于JAX-RS api实现的自己的api JAX-RS是JAVA EE6 引入的一个新技术。 JAX-RS即Java API for RESTful Web Services，是一个Java 编程语言的应用程序接口，支持按照表述性状态转移（REST）架构风格创建Web服务。JAX-RS使用了Java SE5引入的Java注解来简化Web服务的客户端和服务端的开发和部署。 附上JAX-RS api源代码和示例有兴趣研究JAR-RS的同学可以看看 下面是百度百科给的例子 web.xml的设置：12345678910111213141516171819&lt;!--定义Jersey的拦截器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;JerseyServlet&lt;/servlet-name&gt; &lt;servlet-class&gt; com.sun.jersey.spi.spring.container.servlet.SpringServlet &lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;com.sun.jersey.config.property.packages&lt;/param-name&gt; &lt;!--服务类所在的文件夹 --&gt; &lt;param-value&gt;com.mirrors.action&lt;/param-value&gt;&lt;!-- 之所以我定义为com.mirrors.action就是说明此包中类的作用类似于struts中action层类的作用--!&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;JerseyServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/new/*&lt;/url-pattern&gt;&lt;!--项目服务总体前缀 --&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; StudentAction.java一些代码： 12345678910111213141516 @Component @Path("/student")//处理student对象的签注 public class StudentAction &#123; private StudentDao studentdao; public void setStudentdaoStudentDao studentdao)&#123; this.studentdao =studentdao; &#125; @GET//获取方式 @Path("getStudentInfo")//最后前缀 @Produces(&#123; MediaType.APPLICATION_JSON &#125;)//返回类型为一个Student对象的JSON数组 public List&lt;Student&gt; getTrade()&#123; return studentdao.getStudent(); &#125;&#125; 这样一个GET方式的处理就结束了，接下来就是前台提取方式，你可以通过JS控制JSON数组在页面的呈现方式。Jersey共计有4中处理方式，即：@GET,@POST,@DELETE,@PUT。由于Jersey中文资料较少。想学习的可以通过官网API学习。]]></content>
      <categories>
        <category>webservice</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kylin实战(一)]]></title>
    <url>%2Fhexot%2F2018%2F05%2F07%2Fkylin%E5%AE%9E%E6%88%98-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[配置kylin环境前请现确保hadoop,hbase,hive,zookeeper等环境的配置]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka java调用]]></title>
    <url>%2Fhexot%2F2018%2F05%2F06%2Fkafka-java%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[首先附上kafka Api文档 kafkaApi官方文档 打开文档就看到了kafka所有的包如下 org.apache.kafka.clients.consumerorg.apache.kafka.clients.producerorg.apache.kafka.commonorg.apache.kafka.common.configorg.apache.kafka.common.errorsorg.apache.kafka.common.serializationorg.apache.kafka.connect.connectororg.apache.kafka.connect.dataorg.apache.kafka.connect.errorsorg.apache.kafka.connect.sinkorg.apache.kafka.connect.sourceorg.apache.kafka.connect.storageorg.apache.kafka.connect.transformsorg.apache.kafka.connect.utilorg.apache.kafka.streamsorg.apache.kafka.streams.errorsorg.apache.kafka.streams.kstreamorg.apache.kafka.streams.processororg.apache.kafka.streams.state kafka生产者和消费者简单示例]]></content>
      <categories>
        <category>kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka初级教程]]></title>
    <url>%2Fhexot%2F2018%2F05%2F04%2Fkafka%E5%88%9D%E7%BA%A7%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.kafka环境配置1.1 下载kafkakafka官方网站 kafka官方下载页面 我下载的是kafka_2.12-1.0.1.tgz(点击下载链接即可下载) 下载完成后解压到/usr/local/下1234$ mv kafka_2.12-1.0.1.tgz /usr/local/$ cd /usr/local/$ tar -zxvf kafka_2.12-1.0.1.tgz$ mv kafka_2.12-1.0.1 kafka 1.2 下载zookeeperzookeeper下载地址 下载完成后解压到/usr/local 1.3 配置文件修改到zookeeper/conf下修改zoo.cfg文件 修改内容如下 12345tickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeperclientPort=2181 #端口 然后修改kafka的配置文件 kafka/config/server.properties文件,内容如下。 12345678910111213141516171819broker.id=0advertised.listeners=PLAINTEXT://master:9092listeners=PLAINTEXT://master:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/data/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181 #要和zookeeper配置的端口一致zookeeper.connection.timeout.ms=6000 创建2个新文件夹并授权 1234[root@localhost config]# mkdir /data/kafka-logs[root@localhost config]# mkdir /data/zookeeper_data[root@localhost config]# chown lzq996298643:lzq996298643 -R /data/kafka-logs[root@localhost config]# chown lzq996298643:lzq996298643 -R /data/zookeeper_data 启动kafka自带的zookeeper和kafka启动 12345678910111213141516171819202122232425262728293031323334[root@localhost bin]# cd /usr/local/kafka/bin[root@localhost bin]# ll总用量 128-rwxr-xr-x. 1 root root 1335 2月 22 06:26 connect-distributed.sh-rwxr-xr-x. 1 root root 1332 2月 22 06:26 connect-standalone.sh-rwxr-xr-x. 1 root root 861 2月 22 06:26 kafka-acls.sh-rwxr-xr-x. 1 root root 873 2月 22 06:26 kafka-broker-api-versions.sh-rwxr-xr-x. 1 root root 864 2月 22 06:26 kafka-configs.sh-rwxr-xr-x. 1 root root 945 2月 22 06:26 kafka-console-consumer.sh-rwxr-xr-x. 1 root root 944 2月 22 06:26 kafka-console-producer.sh-rwxr-xr-x. 1 root root 871 2月 22 06:26 kafka-consumer-groups.sh-rwxr-xr-x. 1 root root 948 2月 22 06:26 kafka-consumer-perf-test.sh-rwxr-xr-x. 1 root root 869 2月 22 06:26 kafka-delete-records.sh-rwxr-xr-x. 1 root root 863 2月 22 06:26 kafka-log-dirs.sh-rwxr-xr-x. 1 root root 862 2月 22 06:26 kafka-mirror-maker.sh-rwxr-xr-x. 1 root root 886 2月 22 06:26 kafka-preferred-replica-election.sh-rwxr-xr-x. 1 root root 959 2月 22 06:26 kafka-producer-perf-test.sh-rwxr-xr-x. 1 root root 874 2月 22 06:26 kafka-reassign-partitions.sh-rwxr-xr-x. 1 root root 868 2月 22 06:26 kafka-replay-log-producer.sh-rwxr-xr-x. 1 root root 874 2月 22 06:26 kafka-replica-verification.sh-rwxr-xr-x. 1 root root 7579 2月 22 06:26 kafka-run-class.sh-rwxr-xr-x. 1 root root 1376 2月 22 06:26 kafka-server-start.sh-rwxr-xr-x. 1 root root 975 2月 22 06:26 kafka-server-stop.sh-rwxr-xr-x. 1 root root 870 2月 22 06:26 kafka-simple-consumer-shell.sh-rwxr-xr-x. 1 root root 945 2月 22 06:26 kafka-streams-application-reset.sh-rwxr-xr-x. 1 root root 863 2月 22 06:26 kafka-topics.sh-rwxr-xr-x. 1 root root 958 2月 22 06:26 kafka-verifiable-consumer.sh-rwxr-xr-x. 1 root root 958 2月 22 06:26 kafka-verifiable-producer.sh-rwxr-xr-x. 1 root root 1722 2月 22 06:26 trogdor.shdrwxr-xr-x. 2 root root 4096 2月 22 06:26 windows-rwxr-xr-x. 1 root root 867 2月 22 06:26 zookeeper-security-migration.sh-rwxr-xr-x. 1 root root 1393 2月 22 06:26 zookeeper-server-start.sh-rwxr-xr-x. 1 root root 978 2月 22 06:26 zookeeper-server-stop.sh-rwxr-xr-x. 1 root root 968 2月 22 06:26 zookeeper-shell.sh bin目录下面有zookeeper和kafka的启动脚本文件 可以直接使用kafka自带的zookeeper 12[root@localhost bin]# ./zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties[root@localhost bin]# ./kafka-server-start.sh /usr/local/kafka/config/server.properties 当然也可以启动你自己下载的zookeeper 1.4 运行kafka遇到的问题server.properties配置文件中下面两行最好设置本机ip地址不要设置localhost advertised.listeners=PLAINTEXT://master:9092 listeners=PLAINTEXT://master:9092 运行./kafka-server-start.sh /usr/local/kafka/config/server.properties然后访问http://master:9092没有报错就说明启动成功了 2.使用kafka2.1 命令行中测试kafka2.1.1创建一个消息创建者1[root@master bin]# ./kafka-console-producer.sh --broker-list 192.168.0.128:9092 --top test 2.1.2创建一个消息消费者1[root@master bin]# ./kafka-console-consumer.sh --zookeeper 192.168.0.128:2181 --topic test --from-beginning 2.2 kafka命令脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bashsource /etc/profile#前台启动zkif [ $1 = "zk" ]thenzookeeper-server-start.sh /data/kafka_2.11-0.10.1.0/config/zookeeper.properties#后台启动zkelif [ $1 = "zkbg" ]thennohup zookeeper-server-start.sh /data/kafka_2.11-0.10.1.0/config/zookeeper.properties &gt;/dev/null 2&gt;&amp;1 &amp;#关闭zkelif [ $1 = "zkstop" ]thenzookeeper-server-stop.sh#前台启动kafkaelif [ $1 = "kafka" ]thenkafka-server-start.sh /data/kafka_2.11-0.10.1.0/config/server.properties#后台启动kafkaelif [ $1 = "kafkabg" ]thennohup kafka-server-start.sh /data/kafka_2.11-0.10.1.0/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;#关闭kafkaelif [ $1 = "kafkastop" ]thenkafka-server-stop.shelif [ $1 = "consumer" ] #创建一个消费者thenkafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic $2elif [ $1 = "producer" ] #创建一个生产者thenkafka-console-producer.sh --broker-list master:9092 --topic $2elif [ $1 = "create" ]thenkafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic $2 #创建topicelif [ $1 = "list" ]thenkafka-topics.sh --list --zookeeper localhost:2181 #查看topicelif [ $1 = "delete" ]thenkafka-topics.sh --delete --zookeeper localhost:2181 --topic $2 #删除topicelseecho "parameter invalid"fi]]></content>
      <categories>
        <category>kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch初级教程]]></title>
    <url>%2Fhexot%2F2018%2F04%2F14%2Felasticsearch%E5%88%9D%E7%BA%A7%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.安装elasticsearch先去elasticsearch官方网站下载elasticsearch 由于本人平台是centos7,所以本人选择了tar包 下载完成后解压到/usr/local/下 然后进入elasticsearch/config文件夹下修改elasticsearch.yml文件 12345network.host: 192.168.2.215 #配置ip地址http.port: 9200 #配置端口号discovery.zen.ping.unicast.hosts: ["192.168.2.215"] #配置ip地址 配置完成后创建一个es用户 12345678910$ useradd es#创建用户完成后切换到root用户打开/etc/security/limits.conf文件$ gedit /etc/security/limits.conf添加以下两行es hard nofile 65536es soft nofile 65536 然后进入elasticsearch/bin文件夹下切换到es用户启动elasticsearch 1$ ./elasticsearch 然后访问elasticsearch.yml文件里配置的ip地址+端口看到一串json字符串就表示启动成功了,如下 123456789101112131415&#123; &quot;name&quot; : &quot;e17kn5H&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;q1W9ZuXySmag-mmqbAjYYw&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.2.3&quot;, &quot;build_hash&quot; : &quot;c59ff00&quot;, &quot;build_date&quot; : &quot;2018-03-13T10:06:29.741383Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.2.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 2.curl命令操作elasticsearch2.1 创建和删除Index2.1.1 创建一个weather Index12[lzq996298643@localhost ~]$ curl -X PUT '192.168.2.215:9200/qincloud'&#123;"acknowledged":true,"shards_acknowledged":true,"index":"qincloud"&#125; 2.1.2 删除weather index1curl -X DELETE '192.168.2.215:9200/qincloud' 2.2 中文分词器12]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pivot与unpivot使用示例]]></title>
    <url>%2Fhexot%2F2018%2F04%2F13%2Fpivot%E4%B8%8Eunpivot%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[一.下面sql创建一个视图 sql sql 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 不给你们看 哈哈 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282CREATE OR REPLACE VIEW TJ_XQ_NLAS SELECT "NF" , "ZM" , "ZMMC" , "FIV" , "SIX" , "SEVEN", "EIGHT", "NIGHT", "QT" FROM ( SELECT * FROM ( SELECT '2017' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201712' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2016' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201612' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2015' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201512' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2014' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201412' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2013' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201312' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) UNION ALL SELECT * FROM ( SELECT '2012' AS NF , "LEFT"(C.ZM, 1) AS ZM , MAX(J.MC) AS ZMMC , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 5 THEN 1 ELSE 0 END ) AS FIV , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 6 THEN 1 ELSE 0 END ) AS SIX , SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 7 THEN 1 ELSE 0 END ) AS SEVEN, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 8 THEN 1 ELSE 0 END ) AS EIGHT, SUM( CASE WHEN SUBSTR(C.CSRQ, 3, 1) = 9 THEN 1 ELSE 0 END ) AS NIGHT, SUM( CASE WHEN NOT (SUBSTR(C.CSRQ, 3, 1) IN ('5', '6', '7', '8', '9') ) THEN 1 ELSE 0 END ) AS QT FROM GY_DA_JBXX AS C LEFT JOIN GY_XT_ZD AS J ON ( "LEFT"(C.ZM, 1) = J.BM AND J.LB = '1A' ) WHERE EXISTS ( SELECT 1 FROM RP_DA_QMZC AS Q WHERE ( C.SN = Q.ZFSN AND TJNY = '201212' AND ZYBZ = '1' ) ) GROUP BY "LEFT"(C.ZM, 1) ORDER BY "LEFT"(C.ZM, 1) ASC ) ); 二.unpivot示范 12345678910111213141516171819202122232425262728293031323334353637383940414243444546select 分类 , 年龄 , 年份2012, 年份2013, 年份2014, 年份2015, 年份2016, 年份2017from ( select zm , zmmc as 分类 , ln as 年龄 , sum(case when nf = '2012' then num else 0 end) as 年份2012, sum(case when nf = '2013' then num else 0 end) as 年份2013, sum(case when nf = '2014' then num else 0 end) as 年份2014, sum(case when nf = '2015' then num else 0 end) as 年份2015, sum(case when nf = '2016' then num else 0 end) as 年份2016, sum(case when nf = '2017' then num else 0 end) as 年份2017 from ( select zm , zmmc, nf , ln , num from ( select * from tj_xq_nl ) xq unpivot(num for ln in(fiv as '50后', six as '60后', seven as '70后', eight as '80后', night as '90后', qt as '其它')) l where zmmc is not null ) group by zm , zmmc, ln order by zm, ln )]]></content>
      <categories>
        <category>sql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo部署到github]]></title>
    <url>%2Fhexot%2F2018%2F04%2F13%2Fhexo%E9%83%A8%E7%BD%B2%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[hexo官方文档 hexo官方网站主题 在生成以及部署文章之前，需要安装一个扩展：npm install hexo-deployer-git –save然后在hexo服务器文件夹下运行命令: hexo d -g]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker教程]]></title>
    <url>%2Fhexot%2F2018%2F01%2F10%2Fdocker%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一.docker的安装和docker仓库使用docker的安装作者环境是centos7,建议玩docker小伙伴们也在centos7环境上,centos7必须是64位哦 直接运行下面命令安装centos71yum install docker hub.docker.com的注册dockerhub的官方网址是https://hub.docker.com/ 在上面注册一个帐号就可以上传镜像了,和git提交上传代码是一样的． dockerhub的代码是开源的也可以自己搭建一个docker仓库,这个在以后会有专门的教程]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[superset安装教程]]></title>
    <url>%2Fhexot%2F2017%2F12%2F03%2Fsuperset%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装superset本人环境centos7 需要安装python,centos7有自带python 一.安装python 的依赖库和pip1$ yum install libffi-devel python-devel python-pip python-wheel openssl-devel libsasl2-devel openldap-develhi 二.Python virtualenv环境12$ pip install virtualenv #安装virtualenv$ virtualenv venv #进入virtualenv环境 三.安装superset12$ pip install #更新pip$ pip install superset #安装superset 四.设置superset账号和密码123456789$ fabmanager create-admin --app supersetUsername [admin]: adminUser first name [admin]: liaoUser last name [user]: zhqEmail [admin@fab.org]: 996298643@qq.comPassword: Repeat for confirmation: Recognized Database Authentications.Admin User admin created. 五.更新运行初始化运行superset1234567891011$ superset db upgrade #更新superset$ superset init #初始化superset$ superset runserver #运行supersetStarting server with command: gunicorn -w 2 --timeout 60 -b 0.0.0.0:8088 --limit-request-line 0 --limit-request-field_size 0 superset:app[2017-12-03 14:52:30 +0000] [23159] [INFO] Starting gunicorn 19.7.1[2017-12-03 14:52:30 +0000] [23159] [INFO] Listening at: http://0.0.0.0:8088 (23159)[2017-12-03 14:52:30 +0000] [23159] [INFO] Using worker: sync[2017-12-03 14:52:30 +0000] [23164] [INFO] Booting worker with pid: 23164[2017-12-03 14:52:30 +0000] [23165] [INFO] Booting worker with pid: 23165 http://localhost:8088 访问superset]]></content>
      <categories>
        <category>大数据</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo安装实验]]></title>
    <url>%2Fhexot%2F2017%2F12%2F02%2Ftest%2F</url>
    <content type="text"><![CDATA[hexo小白傻瓜安装教程参考博客 hexo-next主题个性化(https://segmentfault.com/a/1190000009544924)hexo主题中添加相册功能(https://www.cnblogs.com/xljzlw/p/5137622.html) 安装hexo之前必须安装node.js和git 以下将从我的环境下说明如何安装node.js和hexo 我的电脑环境是centos7 首先下载和安装node.js 第一步下载node.jsnode.js下载地址(我已经上传到csdn) 第二步安装node.js解压后使用命令 1$ tar --strip-components 1 -xzvf node-v* -C /usr/local 可直接copy到/usr/local对应文件夹下面 使用以下命令如果和下面的结果相同说明已经安装好了node.js 12345$ npm -v5.5.1$ node -vv9.2.0 安装好了node.js后就可以开始安装hexo一.下载安装hexo12$ npm install -g hexo$ npm install -g hexo-cli 安装好hexo以后，在终端输入：1$ hexo 如果没有提示找不到该命令说明安装成功。 二.初始化hexo// 建立一个博客文件夹，并初始化博客，为文件夹的名称，可以随便起名字 $ hexo init ${文件夹} // 进入hexo博客文件夹，${文件夹}为文件夹的名称 $ cd ${文件夹} // node.js的命令，根据博客既定的dependencies配置安装所有的依赖包 $ npm install // 安装hexo admin界面功能 $ npm install –save hexo-admin-qiniu 1234$ hexo init /home/lzq996298643/services/hexo$ cd /home/lzq996298643/services/hexo$ npm install$ npm install --save hexo-admin-qiniu 安装完成后可以在/home/lzq996298643/services/hexo看到博客文件夹 三.发表一篇文章和启动hexo必须要在hexo初始化的文件夹下面(/home/lzq996298643/services/hexo)亲测// 新建一篇文章 hexo new “文章标题” //启动hexo hexo server 如果看到以下输出就表明启动成功1234$ hexo server(node:6187) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. http://localhost:4000 或 http://localhost:4000/admin 访问 hexo代码结构]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhexot%2F2017%2F01%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
</search>
